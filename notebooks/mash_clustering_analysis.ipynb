{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa0f0d95-5e6b-436f-a971-9486d0841329",
   "metadata": {},
   "source": [
    "# Mash based clustering of the dataset\n",
    "\n",
    "This notebook explains the steps for calculating Mash-based clusters, followed by curation of the outliers based on Silhouette scores and save the relevent figures. The notebook can be used as a guide for various different datasets as a starting point. Here, we explain the project called mq_strepto that has 2371 genomes.\n",
    "\n",
    "Note that BGCFlow was independently run and the results of Mash were already present in the BGCFlow directory that will be extracted for the analysis here.\n",
    "\n",
    "We have followed similar steps for secondary round of Mash-clustering where only the starting dataset is updated from all genomes in mq_strepto project to individual primary Mash-cluster assignments created in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73eb0a9-2909-4517-b1eb-d09423fcf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import yaml\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1584e9d-6015-4f45-9ad9-03f417bf376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    notebook_configuration = yaml.safe_load(f)\n",
    "notebook_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27efcf-6f80-40f7-8d3a-dd16942bb27c",
   "metadata": {},
   "source": [
    "### Get Mash results for BGCflow project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8afaa-3c5e-4ec8-b50c-f10919d65187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write samples.csv table to config directory of qc_strepto_ncbi project\n",
    "bgcflow_dir = Path(notebook_configuration[\"bgcflow_dir\"])\n",
    "project_name_1 = \"mq_strepto\"\n",
    "processed_dir_1 = bgcflow_dir / \"data\" / \"processed\" / project_name_1\n",
    "\n",
    "# Read output tables from the processed directory\n",
    "ncbi_meta_table = processed_dir_1 / \"tables\"/ \"df_ncbi_meta.csv\"\n",
    "df_ncbi_meta = pd.read_csv(ncbi_meta_table, index_col= 0)\n",
    "\n",
    "gtdb_meta_table = processed_dir_1 / \"tables\"/ \"df_gtdb_meta_curated.csv\"\n",
    "df_gtdb_meta = pd.read_csv(gtdb_meta_table, index_col= 0)\n",
    "\n",
    "seqfu_meta_table = processed_dir_1 / \"tables\"/ \"df_seqfu_stats.csv\"\n",
    "df_seqfu_meta = pd.read_csv(seqfu_meta_table, index_col= 0)\n",
    "\n",
    "mash_table = processed_dir_1 / \"mash\"/ \"df_mash.csv\"\n",
    "df_mash = pd.read_csv(mash_table, index_col= 0)\n",
    "\n",
    "filters_table = processed_dir_1 / \"tables\" / \"df_filters.csv\"\n",
    "df_filter_quality = pd.read_csv(filters_table, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806c0bb-7be5-4e5d-a85a-296812a8f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mash_original = df_mash.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf820c-236e-49c7-af28-abdf7ce64f52",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clustering of MASH with optimal K-means + Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6415293-a91f-4c06-9bed-2affe4d6e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeansRes(scaled_data, k, alpha_k=0.02):\n",
    "    '''\n",
    "    # Calculating clusters from https://medium.com/towards-data-science/an-approach-for-choosing-number-of-clusters-for-k-means-c28e614ecb2c\n",
    "    Parameters \n",
    "    ----------\n",
    "    scaled_data: matrix \n",
    "        scaled data. rows are samples and columns are features for clustering\n",
    "    k: int\n",
    "        current k for applying KMeans\n",
    "    alpha_k: float\n",
    "        manually tuned factor that gives penalty to the number of clusters\n",
    "    Returns \n",
    "    -------\n",
    "    scaled_inertia: float\n",
    "        scaled inertia value for current k           \n",
    "    '''\n",
    "    \n",
    "    inertia_o = np.square((scaled_data - scaled_data.mean(axis=0))).sum()\n",
    "    # fit k-means\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(scaled_data)\n",
    "    scaled_inertia = kmeans.inertia_ / inertia_o + alpha_k * k\n",
    "    return scaled_inertia\n",
    "\n",
    "def chooseBestKforKMeans(scaled_data, k_range):\n",
    "    ans = []\n",
    "    for k in k_range:\n",
    "        scaled_inertia = kMeansRes(scaled_data, k)\n",
    "        ans.append((k, scaled_inertia))\n",
    "    results = pd.DataFrame(ans, columns = ['k','Scaled Inertia']).set_index('k')\n",
    "    best_k = results.idxmin()[0]\n",
    "    return best_k, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c693d-43f7-4f81-b14c-96c06591d23b",
   "metadata": {},
   "source": [
    "## Perform heirarchical clustering\n",
    "\n",
    "1. Convert distance matrix to similarity\n",
    "2. Compute pairwise distances using Pearson's correlation coefficient to be used as feature tables\n",
    "3. Performing hierarchical clustering using ward.D2 method to get linkage matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7500bb03-86a2-4a1d-becb-b152663b5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.copy()\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50107f-53b5-4295-9808-4c18070cd643",
   "metadata": {},
   "source": [
    "## Plot the K-means adjusted intertia plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1745c95-177f-45d8-86be-97bb521abea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose k range\n",
    "max_range = 30\n",
    "\n",
    "k_range=range(2, max_range)\n",
    "# compute adjusted intertia\n",
    "best_k, results = chooseBestKforKMeans(distances, k_range)\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(results,'o')\n",
    "plt.title('Adjusted Inertia for each K')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Adjusted Inertia')\n",
    "plt.savefig(\"assets/figures/Figure_2/kmeans_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53da96c-022c-4416-bf9e-c51359fd4f00",
   "metadata": {},
   "source": [
    "## Plot sum of Silhoutte score to find optimal clustering at global scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd6f6e-f46d-4564-8b52-371a3baac0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of possible numbers of clusters\n",
    "min_clusters = 2\n",
    "max_clusters = 30\n",
    "\n",
    "# Variables to store the silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Iterate over different numbers of clusters\n",
    "for num_clusters in range(min_clusters, max_clusters+1):\n",
    "    # Use fcluster to assign cluster labels\n",
    "    clusters = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "\n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(distances, clusters)\n",
    "    \n",
    "    # Store the silhouette score\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "silhouette_scores_prefiltering = silhouette_scores.copy()\n",
    "\n",
    "# Plot the silhouette scores against the number of clusters\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(range(min_clusters, max_clusters+1), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score vs Number of Clusters')\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_maxima_plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e2b20d-9efd-41ac-941b-0dd83e3e091f",
   "metadata": {},
   "source": [
    "## Pick the best clusters\n",
    "\n",
    "Based on above plots we manually picked 7 as optimal clusters for the given dataset of mq_strepto porject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6486d4-6620-463c-bfcc-48baaaaf7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8947ce-de20-4962-8e11-6f74bb237833",
   "metadata": {},
   "source": [
    "## Get cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430eeab0-4c44-49c0-95c3-64292972c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Create dataframe assigning genomes to clusters\n",
    "df_mash_clusters_kmeans = pd.DataFrame({'Cluster': clusters}, index=df_similarity.index)\n",
    "\n",
    "# Define the colors for 15 detected clusters\n",
    "color_set_15 = [\"#e6194b\", \"#3cb44b\", \"#ffe119\", \"#0082c8\", \"#f58231\", \"#911eb4\", \"#46f0f0\", \"#f032e6\", \"#d2f53c\", \"#fabebe\", \"#008080\", \"#e6beff\", \"#aa6e28\", \"#fffac8\", \"#800000\"]\n",
    "cluster_list = sorted(df_mash_clusters_kmeans.Cluster.unique())\n",
    "cluster_color_dict = dict(zip(cluster_list, color_set_15[:len(cluster_list)]))\n",
    "\n",
    "# Update df_mash_clusters\n",
    "df_mash_clusters_kmeans[\"Cluster_Color\"] = [cluster_color_dict[df_mash_clusters_kmeans.loc[genome_id, \"Cluster\"]] for genome_id in df_mash_clusters_kmeans.index]\n",
    "df_mash_clusters_kmeans[\"Species\"] = df_gtdb_meta.loc[df_mash_clusters_kmeans.index,\"Species\"]\n",
    "df_mash_clusters_kmeans = df_mash_clusters_kmeans.loc[df_reordered.index, :]\n",
    "\n",
    "df_mash_clusters_kmeans.to_csv(\"assets/tables/df_mash_clusters_main.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1750b-6db2-4443-8313-63bd015250fc",
   "metadata": {},
   "source": [
    "## Plot clustermap with all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122a79b-dc8f-4b3f-b185-95fd7d857696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the clustermap below the dendrogram\n",
    "col_colors = df_mash_clusters_kmeans[\"Cluster_Color\"]\n",
    "sns.set(font_scale=1.0)  # Adjust font size for row labels\n",
    "g = sns.clustermap(df_mash, cmap='Blues_r', \n",
    "                   row_linkage=linkage_matrix, col_linkage=linkage_matrix, \n",
    "                   col_colors= col_colors,\n",
    "                   xticklabels=False, yticklabels=False)\n",
    "\n",
    "# Create a color legend with unique cluster colors\n",
    "color_legend = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cluster_color_dict[cluster],\n",
    "                           markersize=10) for cluster in sorted(cluster_list)]\n",
    "\n",
    "cluster_sizes = df_mash_clusters_kmeans.Cluster.value_counts()\n",
    "labels = [f\"{cluster} (Genomes: {cluster_sizes[cluster]})\" for cluster in sorted(cluster_list)]\n",
    "\n",
    "# Add color legend\n",
    "plt.legend(color_legend, labels, title='Mash cluster ID', bbox_to_anchor=(-1, 1))\n",
    "\n",
    "# Highlight particular species\n",
    "species_list = [\"albidoflavus\", \"anulatus\", \"olivaceus\", \"bacillaris\", \"canus\", \"sp003846175\", \n",
    "                \"papulosus\", \"anthocyanicus\", \"californicus\", \"mirabilis\", \"rochei\", \"virginiae_A\", \n",
    "                \"libani\", \"sp003403055\", \"bikiniensis\"]\n",
    "\n",
    "for selected_species in species_list:\n",
    "    x_min = 0 \n",
    "    y_min = 0 \n",
    "    xy_size = 0\n",
    "    \n",
    "    for idx in range(df_mash_clusters_kmeans.shape[0]):\n",
    "        if selected_species == df_mash_clusters_kmeans.iloc[idx, 2]:\n",
    "            xy_size = xy_size + 1\n",
    "            if x_min == 0:\n",
    "                x_min = idx\n",
    "                y_min = idx      \n",
    "    \n",
    "    highlight = Rectangle((x_min, y_min), xy_size, xy_size, fill=False, edgecolor='black', lw=0.5)  # square with lower-left corner at (0,0), width and height 2\n",
    "    g.ax_heatmap.add_patch(highlight)\n",
    "    g.ax_heatmap.plot()  # Refresh the plot\n",
    "    \n",
    "    # Adding text label\n",
    "    if selected_species == \"olivaceus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+300, y_min-20),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "    elif selected_species == \"anthocyanicus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "    elif selected_species == \"californicus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+800, y_min+100),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "    elif selected_species == \"parvus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "    elif x_min > 1200:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min, y_min+xy_size/2), xytext=(x_min-1000, y_min+xy_size/2),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "    else:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+xy_size/2),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5))\n",
    "\n",
    "plt.savefig(\"assets/figures/Figure_2/mash_clustermap_all.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e545d43-238d-4574-8801-148647be647a",
   "metadata": {},
   "source": [
    "## Silhouette coefficient assessment and filtering of poorly clustered genomes\n",
    "\n",
    "Assess the above clustering using the silhouette coefficient for each of the detected clusters.\n",
    "\n",
    "Create a subset called filtere_data which includes the genomes that have high clustering score (e.g. Silhouette score above 0.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e157d3-87ba-4c0e-bf36-92afb28e4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7\n",
    "\n",
    "# This mapping was manually edited in order to match the ids to the heatmap figure\n",
    "cluster_mapping_dict = {1:2, 2:3, 3:6, 4:7, 5:5, 6:4, 7:1}\n",
    "\n",
    "color_map = {'1': '#e6194b',\n",
    " '2': '#3cb44b',\n",
    " '3': '#ffe119',\n",
    " '4': '#0082c8',\n",
    " '5': '#f58231',\n",
    " '6': '#911eb4',\n",
    " '7': '#46f0f0'}\n",
    "\n",
    "# Select samples above a threshold\n",
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4492c-d59c-4196-9d58-64d673b51459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.copy()\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]\n",
    "\n",
    "\n",
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Compute silhouette coefficient for each sample\n",
    "silhouette_values = silhouette_samples(distances, clusters)\n",
    "\n",
    "df_silhouette = pd.DataFrame({\"Cluster\": clusters, \"Silhouette\": silhouette_values}, index=df_similarity.index)\n",
    "df_silhouette.to_csv(\"assets/tables/df_silhouette_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b54a3f-1917-46e0-9acd-bc82aac96e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples above a threshold\n",
    "data = df_silhouette.copy()\n",
    "filtered_data = data[data[\"Silhouette\"] >= threshold]\n",
    "\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--', label='Cutoff Value')\n",
    "plt.text(3, threshold + 0.05, f'Cutoff: {threshold}', color='black', ha='right', va='center')\n",
    "plt.text(0, 0.9, f'Filtered genomes: {data.shape[0] - filtered_data.shape[0]}', color='grey', ha='left', va='center')\n",
    "\n",
    "plt.title('Silhouette values across 7 clusters for all genomes', fontdict={\"size\": 20})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Silhouette value')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f1b69-4f92-4005-9066-3a1b4b3c8c6f",
   "metadata": {},
   "source": [
    "## Iterate the clustering step till 0.4 cutoff is reached for all genomes\n",
    "\n",
    "The above step of filtering poorly clustered genomes based on Silhouette score is iteratively repeated till we get dataset with all genomes above a threshold of 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c878dd-c0d9-4cba-9834-338aa3d7e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_mapping_dict = {1:2, 2:3, 3:6, 4:7, 5:5, 6:4, 7:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a3ac3a-dff2-4be0-a2b5-cd97e07cf322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[filtered_data.index, filtered_data.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]\n",
    "\n",
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Compute silhouette coefficient for each sample\n",
    "silhouette_values = silhouette_samples(distances, clusters)\n",
    "\n",
    "clusters_updated = [cluster_mapping_dict[cluster_id] for cluster_id in clusters]\n",
    "df_silhouette_filtered_2 = pd.DataFrame({\"Cluster\": clusters_updated, \"Silhouette\": silhouette_values}, index=df_similarity.index)\n",
    "df_silhouette_filtered_2.to_csv(\"assets/tables/df_silhouette_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e3613-c743-408e-9673-a4e20a617c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_silhouette_filtered_2.copy()\n",
    "filtered_data = data[data[\"Silhouette\"] >= threshold]\n",
    "\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--', label='Cutoff Value')\n",
    "plt.text(3, threshold + 0.05, f'Cutoff: {threshold}', color='black', ha='right', va='center')\n",
    "plt.text(0, 0.9, f'Filtered genomes: {data.shape[0] - filtered_data.shape[0]}', color='grey', ha='left', va='center')\n",
    "\n",
    "plt.title('Silhouette values after first filtering', fontdict={\"size\": 20})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Silhouette value')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b260f-771a-40cf-9b5f-957c07e83514",
   "metadata": {},
   "source": [
    "### Second round of filtering\n",
    "\n",
    "The above set of filtered genomes performed better at clustering than original dataset, however there were still 37 genomes that were poorly clsutered. Below we carry out second round of filtering and analyse the clustering on further reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d4c98-fab9-4a09-be1e-8117ae86f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[filtered_data.index, filtered_data.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]\n",
    "\n",
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Compute silhouette coefficient for each sample\n",
    "silhouette_values = silhouette_samples(distances, clusters)\n",
    "\n",
    "clusters_updated = [cluster_mapping_dict[cluster_id] for cluster_id in clusters]\n",
    "df_silhouette_filtered_3 = pd.DataFrame({\"Cluster\": clusters_updated, \"Silhouette\": silhouette_values}, index=df_similarity.index)\n",
    "df_silhouette_filtered_3.to_csv(\"assets/tables/df_silhouette_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434a6dc-c6b8-48ef-96c0-52ef777f2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_silhouette_filtered_3.copy()\n",
    "filtered_data = data[data[\"Silhouette\"] >= threshold]\n",
    "\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--', label='Cutoff Value')\n",
    "plt.text(3, threshold + 0.05, f'Cutoff: {threshold}', color='black', ha='right', va='center')\n",
    "plt.text(0, 0.9, f'Filtered genomes: {data.shape[0] - filtered_data.shape[0]}', color='grey', ha='left', va='center')\n",
    "\n",
    "plt.title('Silhouette values after second filtering', fontdict={\"size\": 20})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Silhouette value')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a675dd5-6af9-4f7e-849e-d9d074eaa05d",
   "metadata": {},
   "source": [
    "### Third round of filtering\n",
    "\n",
    "Another round of filtering was carried out for the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b2fc9-6507-493d-a56c-10920ea089ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[filtered_data.index, filtered_data.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]\n",
    "\n",
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Compute silhouette coefficient for each sample\n",
    "silhouette_values = silhouette_samples(distances, clusters)\n",
    "\n",
    "clusters_updated = [cluster_mapping_dict[cluster_id] for cluster_id in clusters]\n",
    "df_silhouette_filtered_4 = pd.DataFrame({\"Cluster\": clusters_updated, \"Silhouette\": silhouette_values}, index=df_similarity.index)\n",
    "df_silhouette_filtered_4.to_csv(\"assets/tables/df_silhouette_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1afec0-13a6-48b1-9de4-aaf1da86511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_silhouette_filtered_4.copy()\n",
    "filtered_data = data[data[\"Silhouette\"] >= threshold]\n",
    "\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--', label='Cutoff Value')\n",
    "plt.text(3, threshold + 0.05, f'Cutoff: {threshold}', color='black', ha='right', va='center')\n",
    "plt.text(0, 0.9, f'Filtered genomes: {data.shape[0] - filtered_data.shape[0]}', color='grey', ha='left', va='center')\n",
    "\n",
    "plt.title('Silhouette values after third filtering', fontdict={\"size\": 20})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Silhouette value')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_4.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ed204-1307-4482-a480-7513a236f7a2",
   "metadata": {},
   "source": [
    "### Fourth round of filtering\n",
    "\n",
    "Another round of filtering was carried out for the reduced dataset. This round ended up with perfect clustering with all genomes above threshold of 0.4 Silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b20435-bf34-4641-9fa3-87f909c884e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[filtered_data.index, filtered_data.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]\n",
    "\n",
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Compute silhouette coefficient for each sample\n",
    "silhouette_values = silhouette_samples(distances, clusters)\n",
    "\n",
    "clusters_updated = [cluster_mapping_dict[cluster_id] for cluster_id in clusters]\n",
    "df_silhouette_filtered_5 = pd.DataFrame({\"Cluster\": clusters_updated, \"Silhouette\": silhouette_values}, index=df_similarity.index)\n",
    "df_silhouette_filtered_5.to_csv(\"assets/tables/df_silhouette_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e470b1-ad2f-4064-aea2-6a890901a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_silhouette_filtered_5.copy()\n",
    "filtered_data = data[data[\"Silhouette\"] >= threshold]\n",
    "\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--', label='Cutoff Value')\n",
    "plt.text(3, threshold + 0.05, f'Cutoff: {threshold}', color='black', ha='right', va='center')\n",
    "plt.text(0, 0.9, f'Filtered genomes: {data.shape[0] - filtered_data.shape[0]}', color='grey', ha='left', va='center')\n",
    "\n",
    "plt.title('Silhouette values after fourth filtering', fontdict={\"size\": 20})\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Silhouette value')\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_5.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17d9a3-7024-4236-a6a4-e8e00ab531d4",
   "metadata": {},
   "source": [
    "### Plot Silhouette averages before and after removing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b87ab-99ee-4bbf-addd-5fb4689d5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[df_silhouette_filtered_5.index, df_silhouette_filtered_5.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e8a39-74f3-4b27-956b-41a69cb62362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a range of possible numbers of clusters\n",
    "min_clusters = 2\n",
    "max_clusters = 30\n",
    "\n",
    "# Variables to store the silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Iterate over different numbers of clusters\n",
    "for num_clusters in range(min_clusters, max_clusters+1):\n",
    "    # Use fcluster to assign cluster labels\n",
    "    clusters = fcluster(linkage_matrix, t=num_clusters, criterion='maxclust')\n",
    "\n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(distances, clusters)\n",
    "    \n",
    "    # Store the silhouette score\n",
    "    silhouette_scores.append(score)\n",
    "    \n",
    "# Plot the silhouette scores against the number of clusters\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(min_clusters, max_clusters+1), silhouette_scores, marker='o')\n",
    "plt.plot(range(min_clusters, max_clusters+1), silhouette_scores_prefiltering, marker='o')\n",
    "plt.xlabel('Number of MASH clusters (primary)', fontsize=16)\n",
    "plt.ylabel('Average Silhouette score', fontsize=16)\n",
    "\n",
    "# Set tick label size\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_maxima_comparison.png\")\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_maxima_comparison.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe780b-feca-44e1-a07e-323b1fda3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples above a threshold\n",
    "data = df_silhouette.copy()\n",
    "filtered_data = df_silhouette.loc[df_silhouette_filtered_5.index, :]\n",
    "\n",
    "data['Cluster'] = data['Cluster'].apply(lambda x: f'M{x}')\n",
    "filtered_data['Cluster'] = filtered_data['Cluster'].apply(lambda x: f'M{x}')\n",
    "color_map_phylogroups = {f'M{key}': value for key, value in color_map.items()}\n",
    "# Create the boxenplot using the filtered data\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxenplot(x='Cluster', y='Silhouette', data=data, color='lightgray', showfliers=False)\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=data, size=4, color=\"grey\")\n",
    "sns.swarmplot(x='Cluster', y='Silhouette', data=filtered_data, size=4, palette=color_map_phylogroups)\n",
    "plt.axhline(y=threshold, color='gray', linestyle='--')\n",
    "\n",
    "plt.xlabel('Mash clusters', fontsize=16)\n",
    "plt.ylabel('Silhouette scores', fontsize=16)\n",
    "\n",
    "# Set tick label size\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_filter_comparison.png\")\n",
    "plt.savefig(\"assets/figures/Figure_2/silhouette_filter_comparison.svg\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224d878-86fa-44ab-a2d6-f44b395b2c7c",
   "metadata": {},
   "source": [
    "### Reduced dataset by filtering poorly clustered samples\n",
    "\n",
    "At this step, we have a filtered dataset that with good clustering score that will be used for downstream analysis. In the next steps, clustermaps are plotted again for the heatmaps before and after filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9171e40-2c77-4420-93c4-e78bdd8e23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.copy()\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb12697-45c7-41bb-b774-f444f8b25690",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e3338-3b7f-47f5-a9dd-55f29d5673f4",
   "metadata": {},
   "source": [
    "## Get cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652af11-b8b8-4f52-9227-15d249a2fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "# Create dataframe assigning genomes to clusters\n",
    "df_mash_clusters_kmeans = pd.DataFrame({'Cluster': clusters}, index=df_similarity.index)\n",
    "\n",
    "# Update df_mash_clusters\n",
    "df_mash_clusters_kmeans[\"Cluster_Color\"] = [cluster_color_dict[df_mash_clusters_kmeans.loc[genome_id, \"Cluster\"]] for genome_id in df_mash_clusters_kmeans.index]\n",
    "df_mash_clusters_kmeans[\"Species\"] = df_gtdb_meta.loc[df_mash_clusters_kmeans.index,\"Species\"]\n",
    "df_mash_clusters_kmeans = df_mash_clusters_kmeans.loc[df_reordered.index, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97277b23-b390-4ce7-9bfe-bc59b4895638",
   "metadata": {},
   "source": [
    "## Plot clustermap with all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba047d9-da8f-47ee-a885-8a7df225b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mash.index.name = \"\"\n",
    "df_mash.columns.name = \"\"\n",
    "\n",
    "# Plotting the clustermap below the dendrogram\n",
    "col_colors = [df_mash_clusters_kmeans.loc[genome_id, \"Cluster_Color\"] if genome_id in filtered_data.index.tolist() else \"#808080\" for genome_id in df_mash.index]\n",
    "\n",
    "sns.set(font_scale=1.0)  # Adjust font size for row labels\n",
    "g = sns.clustermap(df_mash, cmap='Blues_r', \n",
    "                   row_linkage=linkage_matrix, col_linkage=linkage_matrix, \n",
    "                   col_colors= col_colors,\n",
    "                   xticklabels=False, yticklabels=False)\n",
    "\n",
    "# Create a color legend with unique cluster colors\n",
    "color_legend = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cluster_color_dict[cluster],\n",
    "                           markersize=10) for cluster in sorted(cluster_list)]\n",
    "\n",
    "cluster_sizes = df_mash_clusters_kmeans.Cluster.value_counts()\n",
    "labels = [f\"{cluster} (Genomes: {cluster_sizes[cluster]})\" for cluster in sorted(cluster_list)]\n",
    "\n",
    "# # Add color legend\n",
    "# plt.legend(color_legend, labels, title='Mash cluster ID', bbox_to_anchor=(-1, 1))\n",
    "\n",
    "# Highlighting square\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "species_list = [\"albidoflavus\", \"anulatus\", \"olivaceus\", \"bacillaris\", \"canus\",\n",
    "                \"papulosus\", \"anthocyanicus\", \"californicus\", \"mirabilis\", \"rochei\", \"virginiae_A\", \n",
    "                \"bikiniensis\"]\n",
    "\n",
    "for selected_species in species_list:\n",
    "    x_min = 0 \n",
    "    y_min = 0 \n",
    "    xy_size = 0\n",
    "    \n",
    "    for idx in range(df_mash_clusters_kmeans.shape[0]):\n",
    "        if selected_species == df_mash_clusters_kmeans.iloc[idx, 2]:\n",
    "            xy_size = xy_size + 1\n",
    "            if x_min == 0:\n",
    "                x_min = idx\n",
    "                y_min = idx      \n",
    "    \n",
    "    highlight = Rectangle((x_min, y_min), xy_size, xy_size, fill=False, edgecolor='black', lw=0.5)  # square with lower-left corner at (0,0), width and height 2\n",
    "    g.ax_heatmap.add_patch(highlight)\n",
    "    g.ax_heatmap.plot()  # Refresh the plot\n",
    "    \n",
    "    # Adding text label\n",
    "    if selected_species == \"olivaceus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size/2, y_min+xy_size), xytext=(x_min-xy_size, y_min+600),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "    elif selected_species == \"anthocyanicus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "    elif selected_species == \"californicus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+600, y_min+300),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "    elif selected_species == \"parvus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "    elif x_min > 1200:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min, y_min+xy_size/2), xytext=(x_min-1000, y_min+xy_size/2),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "    else:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+xy_size/2),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=20)\n",
    "\n",
    "plt.savefig(\"assets/figures/Figure_2/mash_clustermap_filtered_all.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c51c9b-e4f8-401b-8366-89b2cb8f421a",
   "metadata": {},
   "source": [
    "# Recluster the reduced Mash matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17fe08-638f-4b6d-8cda-deaf7d6e6b00",
   "metadata": {},
   "source": [
    "## Perform heirarchical clustering\n",
    "\n",
    "1. Convert distance matrix to similarity\n",
    "2. Compute pairwise distances using Pearson's correlation coefficient to be used as feature tables\n",
    "3. Performing hierarchical clustering using ward.D2 method to get linkage matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c1b43-bf13-4e8e-91de-20df32497288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtracting Mash distances from 1 to convert to similarity\n",
    "df_mash = df_mash_original.loc[df_silhouette_filtered_5.index, df_silhouette_filtered_5.index]\n",
    "df_similarity = 1 - df_mash\n",
    "\n",
    "# Computing pairwise distances using Pearson's correlation coefficient\n",
    "distances = squareform(pdist(df_similarity, metric='correlation'))\n",
    "\n",
    "# Performing hierarchical clustering using ward.D2 method\n",
    "linkage_matrix = linkage(distances, method='ward')\n",
    "\n",
    "# Reordering rows and columns of the distance matrix based on clustering\n",
    "ordered_indices = dendrogram(linkage_matrix, no_plot=True)['leaves']\n",
    "df_reordered = df_similarity.iloc[ordered_indices, ordered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5323d-39a7-414c-972d-79e22b503b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca32200-8277-4b4c-8039-e83d63442715",
   "metadata": {},
   "source": [
    "## Get cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d060f4-535c-4c4a-ae65-4670c7b61d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fcluster to assign cluster labels\n",
    "clusters = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
    "\n",
    "cluster_mapping_dict = {1:2, 2:3, 3:6, 4:7, 5:5, 6:4, 7:1}\n",
    "# Create dataframe assigning genomes to clusters\n",
    "df_mash_clusters_kmeans = pd.DataFrame({'Cluster': [cluster_mapping_dict[cluster_id] for cluster_id in clusters]}, index=df_similarity.index)\n",
    "\n",
    "# Update df_mash_clusters\n",
    "df_mash_clusters_kmeans[\"Cluster_Color\"] = [cluster_color_dict[df_mash_clusters_kmeans.loc[genome_id, \"Cluster\"]] for genome_id in df_mash_clusters_kmeans.index]\n",
    "df_mash_clusters_kmeans[\"Species\"] = df_gtdb_meta.loc[df_mash_clusters_kmeans.index,\"Species\"]\n",
    "df_mash_clusters_kmeans = df_mash_clusters_kmeans.loc[df_reordered.index, :]\n",
    "\n",
    "df_mash_clusters_kmeans.to_csv(\"assets/tables/df_mash_clusters_main_reduced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93de3fa6-65c3-4ab3-b854-8fa528ae8b0d",
   "metadata": {},
   "source": [
    "## Plot clustermap with all genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b3cb90-d3c2-4e4d-b321-ef8c583ad427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the clustermap below the dendrogram\n",
    "df_mash.index.name = \"\"\n",
    "df_mash.columns.name = \"\"\n",
    "\n",
    "# Plotting the clustermap below the dendrogram\n",
    "col_colors = [df_mash_clusters_kmeans.loc[genome_id, \"Cluster_Color\"] if genome_id in filtered_data.index.tolist() else \"#808080\" for genome_id in df_mash.index]\n",
    "# col_colors =df_mash_clusters_kmeans.loc[df_mash.index, \"Cluster_Color\"]\n",
    "\n",
    "sns.set(font_scale=1.0)  # Adjust font size for row labels\n",
    "g = sns.clustermap(df_mash, cmap='Blues_r', \n",
    "                   row_linkage=linkage_matrix, col_linkage=linkage_matrix, \n",
    "                   col_colors= col_colors,\n",
    "                   xticklabels=False, yticklabels=False)\n",
    "\n",
    "# Create a color legend with unique cluster colors\n",
    "color_legend = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cluster_color_dict[cluster],\n",
    "                           markersize=10) for cluster in sorted(cluster_list)]\n",
    "\n",
    "cluster_sizes = df_mash_clusters_kmeans.Cluster.value_counts()\n",
    "labels = [f\"{cluster} (Genomes: {cluster_sizes[cluster]})\" for cluster in sorted(cluster_list)]\n",
    "\n",
    "# # Add color legend\n",
    "# plt.legend(color_legend, labels, title='Mash cluster ID', bbox_to_anchor=(-1, 1))\n",
    "\n",
    "# Highlighting square\n",
    "species_list = [\"albidoflavus\", \"anulatus\", \"olivaceus\", \"bacillaris\", \"canus\", \"sp003846175\", \n",
    "                \"papulosus\", \"anthocyanicus\", \"californicus\", \"mirabilis\", \"rochei\", \"virginiae_A\", \n",
    "                \"libani\", \"bikiniensis\"]\n",
    "for selected_species in species_list:\n",
    "    x_min = 0 \n",
    "    y_min = 0 \n",
    "    xy_size = 0\n",
    "    \n",
    "    for idx in range(df_mash_clusters_kmeans.shape[0]):\n",
    "        if selected_species == df_mash_clusters_kmeans.iloc[idx, 2]:\n",
    "            xy_size = xy_size + 1\n",
    "            if x_min == 0:\n",
    "                x_min = idx\n",
    "                y_min = idx      \n",
    "    \n",
    "    highlight = Rectangle((x_min, y_min), xy_size, xy_size, fill=False, edgecolor='black', lw=0.5)  # square with lower-left corner at (0,0), width and height 2\n",
    "    g.ax_heatmap.add_patch(highlight)\n",
    "    g.ax_heatmap.plot()  # Refresh the plot\n",
    "    \n",
    "    # Adding text label\n",
    "    if selected_species == \"olivaceus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size/2, y_min+xy_size), xytext=(x_min+xy_size, y_min+600),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "    elif selected_species == \"mirabilis\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "    elif selected_species == \"californicus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+500, y_min+100),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "    elif selected_species == \"parvus\":\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+200),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "    elif x_min > 1000:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min, y_min+xy_size/2), xytext=(x_min-1000, y_min+xy_size/2),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "    else:\n",
    "        g.ax_heatmap.annotate(selected_species, xy=(x_min+xy_size, y_min+xy_size/2), xytext=(x_min+xy_size+700, y_min+xy_size/2),\n",
    "                 arrowprops=dict(facecolor='black', shrink=0.03, alpha=0.5), fontsize=18)\n",
    "\n",
    "plt.savefig(\"assets/figures/Figure_2/mash_clustermap_reduced.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
